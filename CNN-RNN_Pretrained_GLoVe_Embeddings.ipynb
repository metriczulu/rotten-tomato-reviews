{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RT classification pretrained embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6nXZmVCTR2y",
        "colab_type": "text"
      },
      "source": [
        "##Rotten Tomatoes review classification using Keras without pre-trained embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWKhSdY1Ssrq",
        "colab_type": "code",
        "outputId": "c25ec990-7158-41dc-b54d-56acb742ef39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "!pip install wordvecpy\n",
        "from wordvecpy import TextProcessor, FastVectokenizer\n",
        "!pip install pymagnitude\n",
        "import pymagnitude\n",
        "import timeit"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Collecting wordvecpy\n",
            "  Downloading https://files.pythonhosted.org/packages/84/c9/5b45b3206183cf59c2045a8d50e7b33e9aa552615dd6107f5a0a1827d8cb/wordvecpy-0.5.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wordvecpy) (1.16.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from wordvecpy) (4.28.1)\n",
            "Building wheels for collected packages: wordvecpy\n",
            "  Building wheel for wordvecpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/37/8d/929b022daf780d0597ee8aa6eac33e9b69cd4b09215d1944a1\n",
            "Successfully built wordvecpy\n",
            "Installing collected packages: wordvecpy\n",
            "Successfully installed wordvecpy-0.5\n",
            "Collecting pymagnitude\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/a3/b9a34d22ed8c0ed59b00ff55092129641cdfa09d82f9abdc5088051a5b0c/pymagnitude-0.1.120.tar.gz (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 40.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pymagnitude\n",
            "  Building wheel for pymagnitude (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/c7/98/cb48b9db35f8d1a7827b764dc36c5515179dc116448a47c8a1\n",
            "Successfully built pymagnitude\n",
            "Installing collected packages: pymagnitude\n",
            "Successfully installed pymagnitude-0.1.120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohZ_N8MlC5u7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "df5dae93-fc11-46a5-f412-8dfc6d9996dd"
      },
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imKq5fJc88j8",
        "colab_type": "text"
      },
      "source": [
        "Upload our Rotten Tomatoes reviews and the 200-dimensional twitter pre-trained word embedding .magnitude file for use with pymagnitude."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfzDuTV7TMIQ",
        "colab_type": "code",
        "outputId": "d944da60-736e-467e-9f1c-364ec1d6227f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGoBeu8FUxdp",
        "colab_type": "text"
      },
      "source": [
        "Now we load our dataset into a dataframe and preprocess the review text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ysXo9BEsgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/rotten_tomatoes_reviews.csv\")\n",
        "vectors = pymagnitude.Magnitude(\"/content/drive/My Drive/glove.6B.200d.magnitude\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHD-njRgTxnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.Review, df.Freshness, test_size = 0.2, random_state = 0)\n",
        "\n",
        "x_train_processed = TextProcessor(x_train, lemmatizer='spaCy en')\n",
        "x_test_processed = TextProcessor(x_test, lemmatizer='spaCy en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNLy4iL7U_Zi",
        "colab_type": "text"
      },
      "source": [
        "Now we create generate the integer embeddings and vector dictionary to use as input to, and the weights of, our Keras embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj8tEHJUF-XZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd1e670c-d3ca-4ff6-c223-7f2ed2dbcd76"
      },
      "source": [
        "vectokenizer = FastVectokenizer(x_train_processed.transform(), vectors, x_test_processed.transform())\n",
        "x_train, x_test, vector_dict = vectokenizer.to_keras()\n",
        "max_sentence_length = vectokenizer.max_sentence_length\n",
        "vocab_size = vectokenizer.max_words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC6bp23zVOss",
        "colab_type": "text"
      },
      "source": [
        "The first model we'll make will be a simple CNN classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Is3RGoUlTg",
        "colab_type": "code",
        "outputId": "fff6aaf9-a365-4f90-a5dc-8a7df73149e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import Conv1D, AveragePooling1D, Dropout, SpatialDropout1D\n",
        "from keras.layers import BatchNormalization, MaxPooling1D, Dense, Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "\n",
        "model_input = Input(shape = (max_sentence_length,))\n",
        "layers_cnn = Embedding(vocab_size, 200, embeddings_initializer=Constant(vector_dict), \n",
        "                       input_length=max_sentence_length, trainable=False)(model_input)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 7, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 5, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 3, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 3, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 2, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 1, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Flatten()(layers_cnn)\n",
        "cnn_model_output = Dense(1, activation = 'sigmoid')(layers_cnn)\n",
        "\n",
        "cnn_model = Model(inputs = model_input, outputs = cnn_model_output)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTckxV4PZ4id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6xOLFJcZ8x7",
        "colab_type": "code",
        "outputId": "14aab961-3974-418a-a827-60a3abd48965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "cnn_model.fit(x_train, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 58s 150us/step - loss: 0.5299 - acc: 0.7331\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 45s 117us/step - loss: 0.4497 - acc: 0.7896\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 45s 116us/step - loss: 0.3909 - acc: 0.8242\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 45s 116us/step - loss: 0.3359 - acc: 0.8551\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 45s 116us/step - loss: 0.2868 - acc: 0.8804\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 44s 116us/step - loss: 0.2436 - acc: 0.9006\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 44s 114us/step - loss: 0.2071 - acc: 0.9167\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 44s 114us/step - loss: 0.1787 - acc: 0.9292\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 45s 117us/step - loss: 0.1555 - acc: 0.9390\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 45s 117us/step - loss: 0.1366 - acc: 0.9469\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 45s 116us/step - loss: 0.1218 - acc: 0.9524\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 45s 117us/step - loss: 0.1095 - acc: 0.9574\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 45s 117us/step - loss: 0.0993 - acc: 0.9617\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 45s 117us/step - loss: 0.0919 - acc: 0.9646\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 45s 117us/step - loss: 0.0842 - acc: 0.9679\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 44s 115us/step - loss: 0.0775 - acc: 0.9705\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 44s 116us/step - loss: 0.0740 - acc: 0.9718\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 44s 115us/step - loss: 0.0683 - acc: 0.9742\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 45s 116us/step - loss: 0.0645 - acc: 0.9757\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 44s 115us/step - loss: 0.0613 - acc: 0.9771\n",
            "\n",
            "Time to train: 906.007\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIa2Ffpag8NS",
        "colab_type": "code",
        "outputId": "04642968-7c08-4865-f9b5-072618467fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = cnn_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 9s 96us/step\n",
            "\n",
            "loss is: 0.7529\n",
            "accuracy is: 0.84875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-TyBynwt5He",
        "colab_type": "text"
      },
      "source": [
        "Not bad.  Now to try a simple RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd8GLKbQl6mB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a462dca6-043f-42c1-e635-f1cb1cb0aa71"
      },
      "source": [
        "from keras.layers import Bidirectional, CuDNNLSTM\n",
        "\n",
        "layers_rnn = Embedding(vocab_size, 300)(model_input)\n",
        "layers_rnn = Bidirectional(CuDNNLSTM(128))(layers_rnn)\n",
        "layers_rnn = BatchNormalization()(layers_rnn)\n",
        "layers_rnn = Dropout(.35)(layers_rnn)\n",
        "rnn_model_output = Dense(1, activation = 'sigmoid')(layers_rnn)\n",
        "\n",
        "rnn_model = Model(inputs = model_input, outputs = rnn_model_output)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lNE40P_o315",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYzuf6W_o4cy",
        "colab_type": "code",
        "outputId": "b82ea3e1-7902-40b9-cef9-5425d9ad935a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "rnn_model.fit(x_train, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 86s 224us/step - loss: 0.4318 - acc: 0.7977\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 85s 221us/step - loss: 0.3075 - acc: 0.8689\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 85s 221us/step - loss: 0.2237 - acc: 0.9090\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 84s 220us/step - loss: 0.1551 - acc: 0.9395\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.1084 - acc: 0.9590\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 82s 215us/step - loss: 0.0778 - acc: 0.9714\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 83s 215us/step - loss: 0.0587 - acc: 0.9785\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 82s 214us/step - loss: 0.0454 - acc: 0.9837\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 82s 215us/step - loss: 0.0367 - acc: 0.9870\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 82s 214us/step - loss: 0.0309 - acc: 0.9891\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 82s 214us/step - loss: 0.0275 - acc: 0.9906\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0231 - acc: 0.9922\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 84s 219us/step - loss: 0.0214 - acc: 0.9926\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 84s 219us/step - loss: 0.0189 - acc: 0.9936\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 84s 220us/step - loss: 0.0179 - acc: 0.9938\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 84s 219us/step - loss: 0.0172 - acc: 0.9940\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 84s 220us/step - loss: 0.0150 - acc: 0.9949\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 84s 220us/step - loss: 0.0142 - acc: 0.9953\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 85s 220us/step - loss: 0.0138 - acc: 0.9953\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 84s 219us/step - loss: 0.0124 - acc: 0.9957\n",
            "\n",
            "Time to train: 1676.249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzsa3OKOpC8M",
        "colab_type": "code",
        "outputId": "c29351d0-d013-415f-bf98-88d1d7163e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = cnn_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 9s 94us/step\n",
            "\n",
            "loss is: 0.7529\n",
            "accuracy is: 0.84875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v12BpUqcwxbl",
        "colab_type": "text"
      },
      "source": [
        "**Eh**.  Not good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMD_4jC9xP5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import concatenate\n",
        "comb_para_model = concatenate([layers_cnn, layers_rnn])\n",
        "comb_model_layer = Dense(256, activation = 'selu')(comb_para_model)\n",
        "comb_model_output = Dense(1, activation = 'sigmoid')(comb_model_layer)\n",
        "\n",
        "comb_model = Model(inputs = model_input, outputs = comb_model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be3tUDqwy0Dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comb_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWZ0jFCjzC9B",
        "colab_type": "code",
        "outputId": "2a71d1fb-56c3-4d3a-8216-016d77253ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "comb_model.fit(x_train, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 120s 313us/step - loss: 0.0122 - acc: 0.9958\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 118s 306us/step - loss: 0.0143 - acc: 0.9950\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 117s 306us/step - loss: 0.0132 - acc: 0.9955\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 118s 306us/step - loss: 0.0124 - acc: 0.9959\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 118s 306us/step - loss: 0.0115 - acc: 0.9961\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 118s 308us/step - loss: 0.0116 - acc: 0.9961\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 118s 308us/step - loss: 0.0112 - acc: 0.9962\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 118s 309us/step - loss: 0.0110 - acc: 0.9964\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 118s 308us/step - loss: 0.0109 - acc: 0.9964\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 118s 306us/step - loss: 0.0107 - acc: 0.9964\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 118s 306us/step - loss: 0.0098 - acc: 0.9967\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 117s 306us/step - loss: 0.0098 - acc: 0.9967\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0102 - acc: 0.9966\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0093 - acc: 0.9969\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 117s 306us/step - loss: 0.0095 - acc: 0.9967\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0092 - acc: 0.9969\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0089 - acc: 0.9970\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0092 - acc: 0.9968\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 117s 304us/step - loss: 0.0090 - acc: 0.9970\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0084 - acc: 0.9972\n",
            "\n",
            "Time to train: 2356.568\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9F2vhLzzGg9",
        "colab_type": "code",
        "outputId": "c02be220-02b4-4fd1-d7dc-9300e87b9379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = comb_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 19s 193us/step\n",
            "\n",
            "loss is: 0.84\n",
            "accuracy is: 0.8801041666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a573mJJM6yWn",
        "colab_type": "text"
      },
      "source": [
        "Well, 88% is the best we've gotten out of the NNs so far.  Maybe it's time to train it for another 10 epochs and see if it improves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xrtc4oiHbms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "03ac9341-2045-42d9-acb4-2c3213381c86"
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "comb_model.fit(x_train, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))\n",
        "\n",
        "score = comb_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 117s 304us/step - loss: 0.0080 - acc: 0.9973\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0089 - acc: 0.9970\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 117s 304us/step - loss: 0.0078 - acc: 0.9973\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 117s 304us/step - loss: 0.0082 - acc: 0.9971\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 117s 304us/step - loss: 0.0080 - acc: 0.9973\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 117s 303us/step - loss: 0.0082 - acc: 0.9973\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0080 - acc: 0.9973\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 117s 303us/step - loss: 0.0076 - acc: 0.9974\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0079 - acc: 0.9973\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0078 - acc: 0.9974\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0082 - acc: 0.9972\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0073 - acc: 0.9975\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0075 - acc: 0.9975\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 116s 302us/step - loss: 0.0077 - acc: 0.9974\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 117s 303us/step - loss: 0.0070 - acc: 0.9977\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 117s 303us/step - loss: 0.0072 - acc: 0.9976\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 117s 303us/step - loss: 0.0076 - acc: 0.9974\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0072 - acc: 0.9975\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0070 - acc: 0.9976\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0073 - acc: 0.9976\n",
            "\n",
            "Time to train: 2331.475\n",
            "\n",
            "96000/96000 [==============================] - 18s 188us/step\n",
            "\n",
            "loss is: 0.8939\n",
            "accuracy is: 0.880625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_LW6tcQSO03",
        "colab_type": "text"
      },
      "source": [
        "About the same as before.  Let's try one more\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_llSWFHO5fPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers_crnn = Embedding(vocab_size, 300)(model_input)\n",
        "layers_crnn = Bidirectional(CuDNNLSTM(128, return_sequences=True))(layers_crnn)\n",
        "layers_crnn = SpatialDropout1D(.2)(layers_crnn)\n",
        "layers_crnn = Conv1D(filters = 128, kernel_size = 7, strides = 1, activation = 'relu')(layers_crnn)\n",
        "layers_crnn = BatchNormalization()(layers_crnn)\n",
        "layers_crnn = Conv1D(filters = 128, kernel_size = 5, strides = 1, activation = 'relu')(layers_crnn)\n",
        "layers_crnn = BatchNormalization()(layers_crnn)\n",
        "layers_crnn = Conv1D(filters = 128, kernel_size = 3, strides = 1, activation = 'relu')(layers_crnn)\n",
        "layers_crnn = BatchNormalization()(layers_crnn)\n",
        "layers_crnn = Conv1D(filters = 128, kernel_size = 2, strides = 1, activation = 'relu')(layers_crnn)\n",
        "layers_crnn = BatchNormalization()(layers_crnn)\n",
        "layers_crnn = CuDNNLSTM(128)(layers_crnn)\n",
        "layers_crnn = Dropout(.2)(layers_crnn)\n",
        "layers_crnn = Dense(128, activation = 'relu')(layers_crnn)\n",
        "crnn_model_output = Dense(1, activation = 'sigmoid')(layers_crnn)\n",
        "\n",
        "crnn_model = Model(inputs = model_input, outputs = crnn_model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2iHKkxf83I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKzPVhrMBFpO",
        "colab_type": "code",
        "outputId": "d5e654d2-db3d-4799-d1dc-c5e97fd43e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "crnn_model.fit(x_train, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 119s 310us/step - loss: 0.4409 - acc: 0.7903\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 116s 302us/step - loss: 0.3097 - acc: 0.8691\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.2243 - acc: 0.9107\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.1572 - acc: 0.9402\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 116s 302us/step - loss: 0.1104 - acc: 0.9594\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 116s 302us/step - loss: 0.0802 - acc: 0.9712\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0606 - acc: 0.9789\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.0472 - acc: 0.9840\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.0376 - acc: 0.9875\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0323 - acc: 0.9892\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 117s 305us/step - loss: 0.0269 - acc: 0.9910\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 117s 306us/step - loss: 0.0234 - acc: 0.9924\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 119s 309us/step - loss: 0.0200 - acc: 0.9934\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 119s 309us/step - loss: 0.0179 - acc: 0.9940\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 118s 308us/step - loss: 0.0160 - acc: 0.9947\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 118s 308us/step - loss: 0.0142 - acc: 0.9953\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 118s 308us/step - loss: 0.0135 - acc: 0.9955\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 119s 309us/step - loss: 0.0124 - acc: 0.9959\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 118s 308us/step - loss: 0.0119 - acc: 0.9961\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 118s 307us/step - loss: 0.0109 - acc: 0.9965\n",
            "\n",
            "Time to train: 2346.747\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alAklOz_-oH9",
        "colab_type": "code",
        "outputId": "687ffac6-1a31-46f3-bc01-d0d8869cd4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = crnn_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 20s 205us/step\n",
            "\n",
            "loss is: 0.7913\n",
            "accuracy is: 0.8748125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPG2nGzjEn3K",
        "colab_type": "text"
      },
      "source": [
        "So, still not coming close to 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2OGevmiBM_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers_mini = Embedding(vocab_size, 300)(model_input)\n",
        "layers_mini = Bidirectional(CuDNNLSTM(64, return_sequences = True))(layers_mini)\n",
        "layers_mini = Conv1D(filters = 64, kernel_size = 7, strides = 1, activation = 'relu')(layers_mini)\n",
        "layers_mini = MaxPooling1D(3, strides=1)(layers_mini)\n",
        "layers_mini = Bidirectional(CuDNNLSTM(64, return_sequences = True))(layers_mini)\n",
        "layers_mini = Conv1D(filters = 64, kernel_size = 5, strides = 1, activation = 'relu')(layers_mini)\n",
        "layers_mini = MaxPooling1D(3, strides=1)(layers_mini)\n",
        "layers_mini = Bidirectional(CuDNNLSTM(64, return_sequences = False))(layers_mini)\n",
        "layers_mini = BatchNormalization()(layers_mini)\n",
        "layers_mini = Dropout(.25)(layers_mini)\n",
        "layers_mini = Dense(256, activation = 'relu')(layers_mini)\n",
        "layers_mini = BatchNormalization()(layers_mini)\n",
        "layers_mini = Dropout(.25)(layers_mini)\n",
        "layers_mini = Dense(256, activation = 'relu')(layers_mini)\n",
        "mini_model_output = Dense(1, activation = 'sigmoid')(layers_mini)\n",
        "\n",
        "mini_model = Model(inputs = model_input, outputs = mini_model_output)\n",
        "\n",
        "mini_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPk-1mLG-q9U",
        "colab_type": "code",
        "outputId": "e3509872-352b-4937-9a0e-80050b412cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "mini_model.fit(x_train, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 122s 316us/step - loss: 0.4452 - acc: 0.7913\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.3090 - acc: 0.8698\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 115s 300us/step - loss: 0.2164 - acc: 0.9144\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 115s 301us/step - loss: 0.1472 - acc: 0.9443\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.1021 - acc: 0.9624\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 116s 302us/step - loss: 0.0727 - acc: 0.9740\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.0536 - acc: 0.9809\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.0421 - acc: 0.9850\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0344 - acc: 0.9882\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 115s 301us/step - loss: 0.0286 - acc: 0.9904\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 115s 301us/step - loss: 0.0244 - acc: 0.9917\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.0213 - acc: 0.9927\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 116s 301us/step - loss: 0.0194 - acc: 0.9935\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 116s 302us/step - loss: 0.0184 - acc: 0.9938\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 116s 302us/step - loss: 0.0167 - acc: 0.9944\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0148 - acc: 0.9951\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 116s 302us/step - loss: 0.0130 - acc: 0.9956\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0138 - acc: 0.9954\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0119 - acc: 0.9960\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 116s 303us/step - loss: 0.0116 - acc: 0.9961\n",
            "\n",
            "Time to train: 2324.79\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndz0yBmyGBeq",
        "colab_type": "code",
        "outputId": "4bdc9a77-21f7-4881-9ad8-a528fe555c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = mini_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 27s 283us/step\n",
            "\n",
            "loss is: 1.0435\n",
            "accuracy is: 0.8735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enw8GuyYcRXC",
        "colab_type": "text"
      },
      "source": [
        "Total failure.  Worse than before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCauF43DcVuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}