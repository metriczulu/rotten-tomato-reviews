{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RT classification no pretrained embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6nXZmVCTR2y",
        "colab_type": "text"
      },
      "source": [
        "##Rotten Tomatoes review classification using Keras without pre-trained embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWKhSdY1Ssrq",
        "colab_type": "code",
        "outputId": "257bf162-0d80-4202-d541-644fbe04fbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "!pip install wordvecpy\n",
        "from wordvecpy import TextProcessor\n",
        "import timeit\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Collecting wordvecpy\n",
            "  Downloading https://files.pythonhosted.org/packages/84/c9/5b45b3206183cf59c2045a8d50e7b33e9aa552615dd6107f5a0a1827d8cb/wordvecpy-0.5.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wordvecpy) (1.16.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from wordvecpy) (4.28.1)\n",
            "Building wheels for collected packages: wordvecpy\n",
            "  Building wheel for wordvecpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/37/8d/929b022daf780d0597ee8aa6eac33e9b69cd4b09215d1944a1\n",
            "Successfully built wordvecpy\n",
            "Installing collected packages: wordvecpy\n",
            "Successfully installed wordvecpy-0.5\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfzDuTV7TMIQ",
        "colab_type": "code",
        "outputId": "a74c023a-0a57-4aa8-f570-c999832d63d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGoBeu8FUxdp",
        "colab_type": "text"
      },
      "source": [
        "Now we load our dataset into a dataframe and preprocess the review text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHD-njRgTxnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/rotten_tomatoes_reviews.csv')\n",
        "\n",
        "processor = TextProcessor(df['Review'], lemmatizer='spaCy en')\n",
        "df['Review'] = processor.transform(combined_strings=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNLy4iL7U_Zi",
        "colab_type": "text"
      },
      "source": [
        "Now to create integer sequences for all of the reviews in the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvarw9UHUG4s",
        "colab_type": "code",
        "outputId": "cb9a0942-99f5-468f-adf6-9d02d1117a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.drop(['Freshness'], axis = 1), df[\"Freshness\"], test_size = 0.2, random_state = 0)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(x_train['Review'])\n",
        "\n",
        "max_length = max([len(s.split()) for s in x_train['Review']])\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "x_train_tokens = tokenizer.texts_to_sequences(x_train['Review'])\n",
        "x_test_tokens = tokenizer.texts_to_sequences(x_test['Review'])\n",
        "\n",
        "x_train_pad = pad_sequences(x_train_tokens, maxlen = max_length, padding = 'post')\n",
        "x_test_pad = pad_sequences(x_test_tokens, maxlen = max_length, padding = 'post')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC6bp23zVOss",
        "colab_type": "text"
      },
      "source": [
        "The first model we'll make will be a simple CNN classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Is3RGoUlTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8b7dcc79-6ddd-45b3-a03b-7d3f881b193f"
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import Conv1D, AveragePooling1D, Dropout, SpatialDropout1D\n",
        "from keras.layers import BatchNormalization, MaxPooling1D, Dense, Flatten\n",
        "from keras.layers import Embedding\n",
        "\n",
        "model_input = Input(shape = (max_length,))\n",
        "layers_cnn = Embedding(vocab_size, 300)(model_input)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 7, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 5, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 3, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = SpatialDropout1D(.35)(layers_cnn)\n",
        "layers_cnn = AveragePooling1D(pool_size = 5, strides = 1)(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 3, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 2, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = Conv1D(filters = 128, kernel_size = 1, strides = 1, activation = 'relu')(layers_cnn)\n",
        "layers_cnn = BatchNormalization()(layers_cnn)\n",
        "layers_cnn = SpatialDropout1D(.35)(layers_cnn)\n",
        "layers_cnn = AveragePooling1D(pool_size = 3, strides = 1)(layers_cnn)\n",
        "layers_cnn = Flatten()(layers_cnn)\n",
        "cnn_model_output = Dense(1, activation = 'sigmoid')(layers_cnn)\n",
        "\n",
        "cnn_model = Model(inputs = model_input, outputs = cnn_model_output)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTckxV4PZ4id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6xOLFJcZ8x7",
        "colab_type": "code",
        "outputId": "bcbbd878-f16d-4947-eb33-2215cd7995f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "cnn_model.fit(x_train_pad, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 103s 268us/step - loss: 0.4786 - acc: 0.7669\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 92s 240us/step - loss: 0.2906 - acc: 0.8817\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 92s 240us/step - loss: 0.1627 - acc: 0.9383\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 94s 245us/step - loss: 0.0912 - acc: 0.9664\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 93s 242us/step - loss: 0.0590 - acc: 0.9788\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 94s 246us/step - loss: 0.0440 - acc: 0.9843\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 93s 241us/step - loss: 0.0347 - acc: 0.9879\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 93s 242us/step - loss: 0.0282 - acc: 0.9900\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 93s 241us/step - loss: 0.0240 - acc: 0.9915\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 92s 241us/step - loss: 0.0206 - acc: 0.9926\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 92s 240us/step - loss: 0.0188 - acc: 0.9935\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 91s 238us/step - loss: 0.0166 - acc: 0.9943\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 91s 238us/step - loss: 0.0152 - acc: 0.9947\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 91s 238us/step - loss: 0.0140 - acc: 0.9950\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 91s 237us/step - loss: 0.0121 - acc: 0.9958\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 91s 237us/step - loss: 0.0118 - acc: 0.9960\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 91s 236us/step - loss: 0.0105 - acc: 0.9963\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 91s 236us/step - loss: 0.0098 - acc: 0.9964\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 91s 236us/step - loss: 0.0095 - acc: 0.9967\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 90s 235us/step - loss: 0.0089 - acc: 0.9968\n",
            "\n",
            "Time to train: 1850.952\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIa2Ffpag8NS",
        "colab_type": "code",
        "outputId": "c942868a-212c-4e37-b3d1-5e87c80feee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = cnn_model.evaluate(x_test_pad, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 9s 99us/step\n",
            "\n",
            "loss is: 0.9753\n",
            "accuracy is: 0.87465625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-TyBynwt5He",
        "colab_type": "text"
      },
      "source": [
        "Not bad.  Now to try a simple RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd8GLKbQl6mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Bidirectional, CuDNNLSTM\n",
        "\n",
        "layers_rnn = Embedding(vocab_size, 300)(model_input)\n",
        "layers_rnn = Bidirectional(CuDNNLSTM(128))(layers_rnn)\n",
        "layers_rnn = BatchNormalization()(layers_rnn)\n",
        "layers_rnn = Dropout(.35)(layers_rnn)\n",
        "rnn_model_output = Dense(1, activation = 'sigmoid')(layers_rnn)\n",
        "\n",
        "rnn_model = Model(inputs = model_input, outputs = rnn_model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lNE40P_o315",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYzuf6W_o4cy",
        "colab_type": "code",
        "outputId": "d57c8536-af14-4a88-9dbb-424dd68857e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "rnn_model.fit(x_train_pad, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 85s 223us/step - loss: 0.4337 - acc: 0.7973\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 84s 218us/step - loss: 0.3060 - acc: 0.8708\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 84s 218us/step - loss: 0.2208 - acc: 0.9112\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 84s 218us/step - loss: 0.1539 - acc: 0.9403\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 84s 218us/step - loss: 0.1085 - acc: 0.9592\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 84s 218us/step - loss: 0.0787 - acc: 0.9707\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 84s 218us/step - loss: 0.0597 - acc: 0.9787\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 84s 218us/step - loss: 0.0470 - acc: 0.9832\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 84s 218us/step - loss: 0.0370 - acc: 0.9873\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0321 - acc: 0.9886\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0271 - acc: 0.9905\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0243 - acc: 0.9917\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0219 - acc: 0.9926\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0197 - acc: 0.9932\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0184 - acc: 0.9938\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0168 - acc: 0.9941\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0161 - acc: 0.9946\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0152 - acc: 0.9950\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 83s 217us/step - loss: 0.0140 - acc: 0.9953\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 84s 219us/step - loss: 0.0136 - acc: 0.9954\n",
            "\n",
            "Time to train: 1674.291\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzsa3OKOpC8M",
        "colab_type": "code",
        "outputId": "2dd34fff-b48c-4b70-c9ab-6a9fdd2b1376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = cnn_model.evaluate(x_test_pad, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 9s 97us/step\n",
            "\n",
            "loss is: 0.9753\n",
            "accuracy is: 0.87465625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v12BpUqcwxbl",
        "colab_type": "text"
      },
      "source": [
        "**Eh**.  Not bad either, but not even as good as multinomial naive-bayes or logistic regression.  That's a low bar to hold an LSTM or CNN to.  Let's combine them in parallel and see if we can make it a little better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMD_4jC9xP5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import concatenate\n",
        "comb_para_model = concatenate([layers_cnn, layers_rnn])\n",
        "comb_model_layer = Dense(256, activation = 'selu')(comb_para_model)\n",
        "comb_model_output = Dense(1, activation = 'sigmoid')(comb_model_layer)\n",
        "\n",
        "comb_model = Model(inputs = model_input, outputs = comb_model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be3tUDqwy0Dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comb_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWZ0jFCjzC9B",
        "colab_type": "code",
        "outputId": "31099376-8654-4e73-855e-82c9aa03b9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "comb_model.fit(x_train_pad, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 171s 446us/step - loss: 0.0063 - acc: 0.9978\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 169s 440us/step - loss: 0.0078 - acc: 0.9973\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 168s 438us/step - loss: 0.0067 - acc: 0.9976\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 170s 442us/step - loss: 0.0066 - acc: 0.9977\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 169s 439us/step - loss: 0.0066 - acc: 0.9978\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 168s 438us/step - loss: 0.0065 - acc: 0.9978\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 169s 439us/step - loss: 0.0061 - acc: 0.9979\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 168s 438us/step - loss: 0.0059 - acc: 0.9979\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 168s 439us/step - loss: 0.0058 - acc: 0.9980\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 168s 438us/step - loss: 0.0059 - acc: 0.9979\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 168s 439us/step - loss: 0.0057 - acc: 0.9979\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 171s 445us/step - loss: 0.0054 - acc: 0.9981\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 170s 443us/step - loss: 0.0058 - acc: 0.9980\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 168s 439us/step - loss: 0.0049 - acc: 0.9983\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 168s 438us/step - loss: 0.0052 - acc: 0.9981\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 168s 438us/step - loss: 0.0051 - acc: 0.9982\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 168s 439us/step - loss: 0.0049 - acc: 0.9983\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 168s 438us/step - loss: 0.0048 - acc: 0.9982\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 169s 439us/step - loss: 0.0051 - acc: 0.9982\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 176s 457us/step - loss: 0.0045 - acc: 0.9984\n",
            "\n",
            "Time to train: 3386.357\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9F2vhLzzGg9",
        "colab_type": "code",
        "outputId": "0426061f-2b9e-433a-8dd6-e15efa356073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = comb_model.evaluate(x_test_pad, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 20s 207us/step\n",
            "\n",
            "loss is: 1.0076\n",
            "accuracy is: 0.8743229166666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a573mJJM6yWn",
        "colab_type": "text"
      },
      "source": [
        "Ok, so no improvement.  Maybe with a few extra epochs we could break 90% but the model is already pretty overfit.  Let's try combining CNN and RNN layers together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_llSWFHO5fPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers_crnn = Embedding(vocab_size, 300)(model_input)\n",
        "layers_crnn = Bidirectional(CuDNNLSTM(128, return_sequences=True))(layers_crnn)\n",
        "layers_crnn = SpatialDropout1D(.2)(layers_crnn)\n",
        "layers_crnn = Conv1D(filters = 128, kernel_size = 7, strides = 1, activation = 'relu')(layers_crnn)\n",
        "layers_crnn = BatchNormalization()(layers_crnn)\n",
        "layers_crnn = Conv1D(filters = 128, kernel_size = 5, strides = 1, activation = 'relu')(layers_crnn)\n",
        "layers_crnn = BatchNormalization()(layers_crnn)\n",
        "layers_crnn = Conv1D(filters = 128, kernel_size = 3, strides = 1, activation = 'relu')(layers_crnn)\n",
        "layers_crnn = BatchNormalization()(layers_crnn)\n",
        "layers_crnn = Conv1D(filters = 128, kernel_size = 2, strides = 1, activation = 'relu')(layers_crnn)\n",
        "layers_crnn = BatchNormalization()(layers_crnn)\n",
        "layers_crnn = CuDNNLSTM(128)(layers_crnn)\n",
        "layers_crnn = Dropout(.2)(layers_crnn)\n",
        "layers_crnn = Dense(128, activation = 'relu')(layers_crnn)\n",
        "crnn_model_output = Dense(1, activation = 'sigmoid')(layers_crnn)\n",
        "\n",
        "crnn_model = Model(inputs = model_input, outputs = crnn_model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2iHKkxf83I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKzPVhrMBFpO",
        "colab_type": "code",
        "outputId": "e5820a9f-8594-4e8a-eeba-abffef02b428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "crnn_model.fit(x_train_pad, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.4925 - acc: 0.7423\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 121s 314us/step - loss: 0.3397 - acc: 0.8536\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.2574 - acc: 0.8950\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 120s 314us/step - loss: 0.1880 - acc: 0.9265\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 120s 314us/step - loss: 0.1350 - acc: 0.9488\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0984 - acc: 0.9635\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0735 - acc: 0.9733\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0575 - acc: 0.9795\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0449 - acc: 0.9843\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0367 - acc: 0.9871\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 121s 314us/step - loss: 0.0304 - acc: 0.9895\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 121s 314us/step - loss: 0.0264 - acc: 0.9910\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 121s 314us/step - loss: 0.0224 - acc: 0.9923\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 121s 314us/step - loss: 0.0211 - acc: 0.9929\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 121s 314us/step - loss: 0.0181 - acc: 0.9939\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0169 - acc: 0.9944\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0149 - acc: 0.9950\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 121s 316us/step - loss: 0.0139 - acc: 0.9953\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0126 - acc: 0.9956\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 121s 315us/step - loss: 0.0123 - acc: 0.9959\n",
            "\n",
            "Time to train: 2420.76\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alAklOz_-oH9",
        "colab_type": "code",
        "outputId": "cbbbe343-d2ca-432f-d018-a70173eb2920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = crnn_model.evaluate(x_test_pad, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 21s 217us/step\n",
            "\n",
            "loss is: 0.8362\n",
            "accuracy is: 0.8773020833333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPG2nGzjEn3K",
        "colab_type": "text"
      },
      "source": [
        "Wow, that's even worse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2OGevmiBM_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers_mini = Embedding(vocab_size, 300)(model_input)\n",
        "layers_mini = Bidirectional(CuDNNLSTM(64, return_sequences = True))(layers_mini)\n",
        "layers_mini = Conv1D(filters = 64, kernel_size = 7, strides = 1, activation = 'relu')(layers_mini)\n",
        "layers_mini = MaxPooling1D(3, strides=1)(layers_mini)\n",
        "layers_mini = Bidirectional(CuDNNLSTM(64, return_sequences = True))(layers_mini)\n",
        "layers_mini = Conv1D(filters = 64, kernel_size = 5, strides = 1, activation = 'relu')(layers_mini)\n",
        "layers_mini = MaxPooling1D(3, strides=1)(layers_mini)\n",
        "layers_mini = Bidirectional(CuDNNLSTM(64, return_sequences = False))(layers_mini)\n",
        "layers_mini = BatchNormalization()(layers_mini)\n",
        "layers_mini = Dropout(.25)(layers_mini)\n",
        "layers_mini = Dense(256, activation = 'relu')(layers_mini)\n",
        "layers_mini = BatchNormalization()(layers_mini)\n",
        "layers_mini = Dropout(.25)(layers_mini)\n",
        "layers_mini = Dense(256, activation = 'relu')(layers_mini)\n",
        "mini_model_output = Dense(1, activation = 'sigmoid')(layers_mini)\n",
        "\n",
        "mini_model = Model(inputs = model_input, outputs = mini_model_output)\n",
        "\n",
        "mini_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPk-1mLG-q9U",
        "colab_type": "code",
        "outputId": "6f99f91e-9058-4eee-dc55-c10ac2ede2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "t0=timeit.default_timer()\n",
        "mini_model.fit(x_train_pad, y_train, epochs = 20, batch_size = 128)\n",
        "t1=timeit.default_timer()\n",
        "print('\\nTime to train: {}\\n'.format(round(t1-t0, 3)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "384000/384000 [==============================] - 128s 333us/step - loss: 0.4423 - acc: 0.7924\n",
            "Epoch 2/20\n",
            "384000/384000 [==============================] - 124s 322us/step - loss: 0.3076 - acc: 0.8696\n",
            "Epoch 3/20\n",
            "384000/384000 [==============================] - 124s 323us/step - loss: 0.2151 - acc: 0.9135\n",
            "Epoch 4/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.1456 - acc: 0.9439\n",
            "Epoch 5/20\n",
            "384000/384000 [==============================] - 124s 322us/step - loss: 0.1002 - acc: 0.9630\n",
            "Epoch 6/20\n",
            "384000/384000 [==============================] - 124s 322us/step - loss: 0.0719 - acc: 0.9741\n",
            "Epoch 7/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.0526 - acc: 0.9812\n",
            "Epoch 8/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.0419 - acc: 0.9851\n",
            "Epoch 9/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.0331 - acc: 0.9883\n",
            "Epoch 10/20\n",
            "384000/384000 [==============================] - 124s 322us/step - loss: 0.0275 - acc: 0.9904\n",
            "Epoch 11/20\n",
            "384000/384000 [==============================] - 123s 320us/step - loss: 0.0243 - acc: 0.9914\n",
            "Epoch 12/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.0200 - acc: 0.9930\n",
            "Epoch 13/20\n",
            "384000/384000 [==============================] - 123s 322us/step - loss: 0.0178 - acc: 0.9939\n",
            "Epoch 14/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.0165 - acc: 0.9943\n",
            "Epoch 15/20\n",
            "384000/384000 [==============================] - 123s 322us/step - loss: 0.0141 - acc: 0.9952\n",
            "Epoch 16/20\n",
            "384000/384000 [==============================] - 123s 322us/step - loss: 0.0131 - acc: 0.9955\n",
            "Epoch 17/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.0128 - acc: 0.9959\n",
            "Epoch 18/20\n",
            "384000/384000 [==============================] - 124s 323us/step - loss: 0.0126 - acc: 0.9958\n",
            "Epoch 19/20\n",
            "384000/384000 [==============================] - 123s 320us/step - loss: 0.0120 - acc: 0.9961\n",
            "Epoch 20/20\n",
            "384000/384000 [==============================] - 123s 321us/step - loss: 0.0112 - acc: 0.9962\n",
            "\n",
            "Time to train: 2475.07\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndz0yBmyGBeq",
        "colab_type": "code",
        "outputId": "01c5b59a-b4d9-4feb-85de-1fcf76992a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "score = mini_model.evaluate(x_test_pad, y_test)\n",
        "\n",
        "print('\\nloss is: ' + str(score[0].round(4)))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96000/96000 [==============================] - 29s 304us/step\n",
            "\n",
            "loss is: 0.9492\n",
            "accuracy is: 0.8753541666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JCUrYTFMGKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}